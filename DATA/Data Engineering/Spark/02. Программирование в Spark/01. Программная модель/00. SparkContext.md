
---

## ‚úÖ –ö–∞–∫ —Å–æ–∑–¥–∞—Ç—å `SparkContext` –≤ PySpark

`SparkContext` ‚Äî —ç—Ç–æ **—Ç–æ—á–∫–∞ –≤—Ö–æ–¥–∞ –≤ Spark** –∏ –æ—Å–Ω–æ–≤–Ω–æ–π –æ–±—ä–µ–∫—Ç –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å RDD.

---

### üß© –ü—Ä–æ—Å—Ç–µ–π—à–∏–π –ø—Ä–∏–º–µ—Ä:

```python
from pyspark import SparkConf, SparkContext

# 1. –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
conf = SparkConf().setAppName("MyFirstApp").setMaster("local[*]")

# 2. –°–æ–∑–¥–∞–µ–º SparkContext
sc = SparkContext(conf=conf)

# 3. –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
rdd = sc.parallelize([1, 2, 3, 4, 5])
print(rdd.count())  # –í—ã–≤–æ–¥: 5

# 4. –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º SparkContext –≤ –∫–æ–Ω—Ü–µ
sc.stop()
```

---

### üîç –ß—Ç–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç –∫–æ–¥?

| –°—Ç—Ä–æ–∫–∞ | –û–ø–∏—Å–∞–Ω–∏–µ |
|-------|----------|
| `SparkConf()` | –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è |
| `.setAppName(...)` | –ó–∞–¥–∞—ë—Ç –∏–º—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è (–æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è –≤ UI) |
| `.setMaster(...)` | –£–∫–∞–∑—ã–≤–∞–µ—Ç, –≥–¥–µ –∑–∞–ø—É—Å–∫–∞—Ç—å Spark: –ª–æ–∫–∞–ª—å–Ω–æ –∏–ª–∏ –≤ –∫–ª–∞—Å—Ç–µ—Ä–µ |
| `SparkContext(conf=...)` | –°–æ–∑–¥–∞—ë—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç, —á–µ—Ä–µ–∑ –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–±–æ—Ç–∞—é—Ç –≤—Å–µ RDD |
| `sc.parallelize(...)` | –°–æ–∑–¥–∞—ë—Ç RDD –∏–∑ –ª–æ–∫–∞–ª—å–Ω–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏ |
| `sc.textFile(...)` | –ß–∏—Ç–∞–µ—Ç —Ñ–∞–π–ª –∫–∞–∫ RDD |
| `sc.stop()` | –ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É —Å Spark |

---

## –°–æ–∑–¥–∞–Ω–∏–µ SparkContext –Ω–∞–ø—Ä—è–º—É—é —Å –ø–æ–º–æ—â—å—é –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
```python
from pyspark import SparkConf, SparkContext

conf = SparkConf().setAppName("MyApp").setMaster("local[*]")
with SparkContext(conf=conf) as sc:
    rdd = sc.parallelize([1, 2, 3])
    print(rdd.count())
# sc –±—É–¥–µ—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω –ø–æ—Å–ª–µ –≤—ã—Ö–æ–¥–∞ –∏–∑ with
```

## –°–æ–∑–¥–∞–Ω–∏–µ SparkContext —á–µ—Ä–µ–∑ SparkSession —Å –ø–æ–º–æ—â—å—é –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
```python
from pyspark.sql import SparkSession

with SparkSession.builder.appName("MyApp").getOrCreate() as spark:
    sc = spark.sparkContext
    rdd = sc.parallelize([1, 2, 3])
    print(rdd.count())  # ‚úÖ –†–∞–±–æ—Ç–∞–µ—Ç –≤–Ω—É—Ç—Ä–∏ with
# SparkSession –∏ SparkContext –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç—Å—è –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ –∏–∑ with
```

## üîÅ –ö–∞–∫ –ø–æ–ª—É—á–∏—Ç—å `SparkContext` –∏–∑ `SparkSession` (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è)

–í Spark 2.x+ —Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `SparkSession`, –∞ `SparkContext` –ø–æ–ª—É—á–∞—Ç—å –∏–∑ –Ω–µ—ë:

```python
from pyspark.sql import SparkSession

# 1. –°–æ–∑–¥–∞–µ–º SparkSession
spark = SparkSession.builder \
    .appName("MyFirstApp") \
    .getOrCreate()

# 2. –ü–æ–ª—É—á–∞–µ–º SparkContext
sc = spark.sparkContext

# 3. –ò—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
rdd = sc.parallelize([1, 2, 3, 4, 5])
print(rdd.count())

# 4. –ú–æ–∂–Ω–æ –æ—Å—Ç–∞–≤–∏—Ç—å SparkSession –æ—Ç–∫—Ä—ã—Ç—ã–º –∏–ª–∏ –∑–∞–∫—Ä—ã—Ç—å
sc.stop()  # –∏–ª–∏ spark.stop() ‚Äî –æ–±–∞ –º–µ—Ç–æ–¥–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã
```

---

## ‚öôÔ∏è –ü–æ–ª–µ–∑–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ `SparkContext`

```python
conf = SparkConf().setAppName("MyApp") \
                  .setMaster("local[*]") \
                  .set("spark.executor.memory", "4g") \
                  .set("spark.driver.memory", "2g") \
                  .set("spark.serializer", "org.apache.spark.serializer.KryoSerializer")
```

> –≠—Ç–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ:
```bash
spark-submit \
  --master local[*] \
  --executor-memory 4g \
  --driver-memory 2g \
  --num-executors 4 \
  --conf spark.serializer=org.apache.spark.serializer.KryoSerializer \
  --conf spark.rdd.compress=true \
  --conf spark.sql.shuffle.partitions=8 \
  your_script.py
```

---

## üìå –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:

- –î–ª—è –Ω–æ–≤—ã—Ö –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–π `SparkSession`, –Ω–æ –∑–Ω–∞–π, —á—Ç–æ –≤–Ω—É—Ç—Ä–∏ –≤—Å—ë —Ä–∞–≤–Ω–æ —Ä–∞–±–æ—Ç–∞–µ—Ç `SparkContext`.
- –ü—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å RDD –≤—Å–µ–≥–¥–∞ –¥–æ—Å—Ç—É–ø–µ–Ω —á–µ—Ä–µ–∑ `spark.sparkContext`
- –ù–µ –∑–∞–±—ã–≤–∞–π –≤—ã–∑—ã–≤–∞—Ç—å `sc.stop()` –∏–ª–∏ `spark.stop()` –≤ –∫–æ–Ω—Ü–µ, —á—Ç–æ–±—ã –æ—Å–≤–æ–±–æ–¥–∏—Ç—å —Ä–µ—Å—É—Ä—Å—ã

---
## üîπ –°–æ–∑–¥–∞–Ω–∏–µ SparkContext

### 1. –ß–µ—Ä–µ–∑ SparkSession (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è):
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("MyApp").getOrCreate()
sc = spark.sparkContext
```

### 2. –ù–∞–ø—Ä—è–º—É—é (—É—Å—Ç–∞—Ä–µ–≤—à–∏–π —Å–ø–æ—Å–æ–±):
```python
from pyspark import SparkConf, SparkContext

conf = SparkConf().setAppName("MyApp").setMaster("local[*]")
sc = SparkContext(conf=conf)
```

### 3. –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è:
```python
rdd = sc.parallelize(range(10))
print(rdd.collect())
```

### 4. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã:
```python
sc.stop()
# –∏–ª–∏
spark.stop()
```

---
